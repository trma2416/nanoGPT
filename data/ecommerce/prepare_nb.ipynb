{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e19cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import openai\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import language_tool_python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44e54059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dotenv_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '.env'))\n",
    "dotenv_path = \"Users/pc/Documents/CSPB/CSPB 3112/nanoGPT/.env\"\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c92b5f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to clean our input data\n",
    "def clean_txt(text):\n",
    "    text = str(text).strip() #remove leading and trailing whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text) #fix any unneccessary whitespace\n",
    "    text = re.sub(r'^\\x00-\\x7F]+', '', text) #remove any characters non-ASCII\n",
    "    return text\n",
    "#used to split our description on each row into the new column titled items\n",
    "def split(text):\n",
    "    txt_lst = text.split(\"-\")\n",
    "    return txt_lst[0]\n",
    "\n",
    "def split2(txt):\n",
    "    txt_lst = txt.split(\"-\")\n",
    "    return txt_lst[1]\n",
    "    \n",
    "#format the data in a conversational format\n",
    "def format_row(row):\n",
    "    return f\"Customer: Tell me about the {row['item']}.\\nAgent: The {row['item']} is {row['description']}.\\n\"\n",
    "\n",
    "#some of our descriptions lack correct sentence structure which is an issue for training\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "def fix_grammar(txt: str) -> str:\n",
    "    #edge case\n",
    "    if not txt.strip():\n",
    "        print(\"No text provided\")\n",
    "        return txt\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        response = client.chat.completions.create(model=\"gpt-4-turbo\", \n",
    "                                            messages=[{\"role\": \"system\", \"content\": (\"You are a language expert, specializing in spelling correction and correcting sentence structure. \"\n",
    "                                                                                     \"Return in this format: \\n\\ncustomer: <cleaned>\\nagent: <cleaned>\\n\\n\"\n",
    "                                                                                     \"Preserve as much of the vocabulary and technical terms as possible whilest maintaining articulate and clear phrases\"\n",
    "                                                                                     )},\n",
    "                                                      {\"role\": \"user\", \"content\": txt}], \n",
    "                                            temperature=0.2,\n",
    "                                            max_tokens=4000)\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return txt\n",
    "\n",
    "# Alternative method as compared to making API calls to chatGPT    \n",
    "#tool = language_tool_python.LanguageTool('en-US')\n",
    "#def corr_grammar(txt):\n",
    "    #matches = tool.check(txt)\n",
    "    #if len(matches) > 0:\n",
    "        #return tool.correct(txt, matches[0])\n",
    "    #return tool.correct(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12e6447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in our data\n",
    "df = pd.read_csv(\"sample-data.csv\")\n",
    "\n",
    "#our item is hidden in our description so we need to extract that and create a new column\n",
    "df[\"item\"] = df[\"description\"].apply(split)\n",
    "df[\"description\"] = df[\"description\"].apply(split2)\n",
    "df.dropna(subset=[\"description\", \"item\"], inplace=True)\n",
    "#clean up our data\n",
    "for col in [\"id\", \"description\", \"item\"]:\n",
    "    df[col] = df[col].apply(clean_txt)\n",
    "    \n",
    "\n",
    "#finally reformat it so it can be written into a text file\n",
    "formatted = df.apply(format_row, axis=1) #apply to row via axis=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "564f4e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been reformatted!\n",
      "Length of original file:  89347\n",
      "Data is cleaned and ready to be written into file!\n",
      "Length of cleaned data is:  18418\n",
      "Your txt file is ready!\n"
     ]
    }
   ],
   "source": [
    "with open(\"train.txt\", \"w\", encoding = 'utf-8') as f:\n",
    "    f.writelines(formatted)\n",
    "print(\"Data has been reformatted!\")\n",
    "\n",
    "with open(\"train.txt\", \"r\", encoding='utf-8') as file:\n",
    "    original = file.read()\n",
    "#if len(original) > 0:\n",
    "    #print(original[:100]) #first 100 characters to ensure that original is stroring correct data\n",
    "    #print(\"File is ready to make API calls!\")\n",
    "print(\"Length of original file: \", len(original))\n",
    "cleaned_data = fix_grammar(original)\n",
    "print(\"Data is cleaned and ready to be written into file!\")\n",
    "print(\"Length of cleaned data is: \", len(cleaned_data))\n",
    "\n",
    "time.sleep(5)\n",
    "with open(\"train.txt\", \"w\", encoding='utf-8') as tf:\n",
    "    tf.write(cleaned_data)\n",
    "    \n",
    "print(\"Your txt file is ready!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2874d99a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
